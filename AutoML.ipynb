{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eligible-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 18, 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-hunter",
   "metadata": {},
   "source": [
    "Here's just a couple of attempts with AutoML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dense-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerocessing for FEDOT\n",
    "from fedot.core.data.data import InputData\n",
    "from fedot.core.repository.dataset_types import DataTypesEnum\n",
    "from fedot.core.repository.tasks import Task, TaskTypesEnum, TsForecastingParams\n",
    "\n",
    "# FEDOT \n",
    "from fedot.core.data.data_split import train_test_data_setup\n",
    "from fedot.api.main import Fedot\n",
    "from fedot.core.pipelines.pipeline import Pipeline\n",
    "from fedot.core.pipelines.node import PrimaryNode, SecondaryNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dynamic-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autots import AutoTS\n",
    "from autots.evaluator.auto_ts import fake_regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-station",
   "metadata": {},
   "source": [
    "### FEDOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "racial-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_excel('data/X_train_extern.xlsx', index_col=0)\n",
    "y_train = pd.read_excel('data/y_train_feat_eng.xlsx', index_col=0)\n",
    "X_test = pd.read_excel('data/X_test_extern.xlsx', index_col=0)\n",
    "y_test = pd.read_excel('data/y_test_feat_eng.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "apparent-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['company'] = X_train['company'].astype('category')\n",
    "X_test['company'] = X_test['company'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "genuine-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred, order=2):\n",
    "    if not isinstance(y_true, np.ndarray):\n",
    "        y_true = np.asarray(y_true)\n",
    "    if not isinstance(y_pred, np.ndarray):\n",
    "        y_pred = np.asarray(y_pred)\n",
    "    return 100*np.mean(2*np.linalg.norm(y_true-y_pred, ord=order))/(np.linalg.norm(y_true, ord=order)+np.linalg.norm(y_pred, ord=order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "square-upper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1816, 64), (1816, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "handled-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task(TaskTypesEnum.ts_forecasting,\n",
    "            TsForecastingParams(forecast_length=10))\n",
    "\n",
    "train_idx = X_train.index\n",
    "X_train_values = X_train.values\n",
    "\n",
    "train_input = InputData(idx=train_idx,\n",
    "                        features=X_train_values,\n",
    "                        target=y_train,\n",
    "                        task=task,\n",
    "                        data_type=DataTypesEnum.ts)\n",
    "train_data, test_data = train_test_data_setup(train_input, validation_blocks=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "novel-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Fedot(problem='ts_forecasting',\n",
    "              task_params=task.task_params,\n",
    "              timeout=5,\n",
    "              n_jobs=1,\n",
    "              cv_folds=4, validation_blocks=4, preset='fast_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "active-irish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/api/api_utils/assumptions/assumptions_handler.py\", line 60, in fit_assumption_and_check_correctness\n",
      "    pipeline.fit(data_train)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/pipeline.py\", line 146, in fit\n",
      "    train_predicted = self._fit(input_data=copied_input_data)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/pipeline.py\", line 110, in _fit\n",
      "    train_predicted = self.root_node.fit(input_data=input_data)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/node.py\", line 397, in fit\n",
      "    secondary_input = self._input_from_parents(input_data=input_data, parent_operation='fit')\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/node.py\", line 437, in _input_from_parents\n",
      "    parent_operation)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/node.py\", line 477, in _combine_parents\n",
      "    prediction = parent.fit(input_data=input_data)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/node.py\", line 397, in fit\n",
      "    secondary_input = self._input_from_parents(input_data=input_data, parent_operation='fit')\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/node.py\", line 437, in _input_from_parents\n",
      "    parent_operation)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/node.py\", line 477, in _combine_parents\n",
      "    prediction = parent.fit(input_data=input_data)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/node.py\", line 309, in fit\n",
      "    return super().fit(input_data)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/node.py\", line 183, in fit\n",
      "    data=input_data)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/operations/operation.py\", line 86, in fit\n",
      "    predict_train = self.predict_for_fit(self.fitted_operation, data, params)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/operations/operation.py\", line 116, in predict_for_fit\n",
      "    return self._predict(fitted_operation, data, params, output_mode, is_fit_stage=True)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/operations/operation.py\", line 128, in _predict\n",
      "    predict_data=data)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/operations/evaluation/time_series.py\", line 153, in predict_for_fit\n",
      "    prediction = trained_operation.transform_for_fit(predict_data)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/operations/evaluation/operation_implementations/data_operations/ts_transformations.py\", line 94, in transform_for_fit\n",
      "    target, forecast_length, old_idx)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/operations/evaluation/operation_implementations/data_operations/ts_transformations.py\", line 193, in _apply_transformation_for_fit\n",
      "    transformed_cols, new_target, new_idx)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/operations/evaluation/operation_implementations/data_operations/ts_transformations.py\", line 208, in stack_by_type_fit\n",
      "    return stack_function(all_features, all_target, all_idx, features, target, idx)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/operations/evaluation/operation_implementations/data_operations/ts_transformations.py\", line 230, in _stack_multi_variable\n",
      "    all_features = np.hstack((all_features, features))\n",
      "  File \"<__array_function__ internals>\", line 6, in hstack\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/numpy/core/shape_base.py\", line 346, in hstack\n",
      "    return _nx.concatenate(arrs, 1)\n",
      "  File \"<__array_function__ internals>\", line 6, in concatenate\n",
      "ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1747 and the array at index 1 has size 1696\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Initial pipeline fit was failed due to: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1747 and the array at index 1 has size 1696. Check pipeline structure and the correctness of the data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/api/api_utils/assumptions/assumptions_handler.py\u001b[0m in \u001b[0;36mfit_assumption_and_check_correctness\u001b[0;34m(self, pipeline, pipelines_cache, preprocessing_cache)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtry_load_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipelines_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, input_data, time_constraint, n_jobs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtime_constraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mtrain_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopied_input_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, input_data, process_state_dict, fitted_operations)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mcomputation_time_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitted_operation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputation_time\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mtrain_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcomputation_time_update\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/node.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, input_data, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0msecondary_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_from_parents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/node.py\u001b[0m in \u001b[0;36m_input_from_parents\u001b[0;34m(self, input_data, parent_operation)\u001b[0m\n\u001b[1;32m    436\u001b[0m         parent_results, _ = _combine_parents(parent_nodes, input_data,\n\u001b[0;32m--> 437\u001b[0;31m                                              parent_operation)\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0msecondary_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataMerger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/node.py\u001b[0m in \u001b[0;36m_combine_parents\u001b[0;34m(parent_nodes, input_data, parent_operation)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mparent_operation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m             \u001b[0mparent_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/node.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, input_data, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0msecondary_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_from_parents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/node.py\u001b[0m in \u001b[0;36m_input_from_parents\u001b[0;34m(self, input_data, parent_operation)\u001b[0m\n\u001b[1;32m    436\u001b[0m         parent_results, _ = _combine_parents(parent_nodes, input_data,\n\u001b[0;32m--> 437\u001b[0;31m                                              parent_operation)\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0msecondary_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataMerger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/node.py\u001b[0m in \u001b[0;36m_combine_parents\u001b[0;34m(parent_nodes, input_data, parent_operation)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mparent_operation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m             \u001b[0mparent_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/node.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, input_data, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/pipelines/node.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    182\u001b[0m                 self.fitted_operation, operation_predict = self.operation.fit(params=self._parameters,\n\u001b[0;32m--> 183\u001b[0;31m                                                                               data=input_data)\n\u001b[0m\u001b[1;32m    184\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_time_in_seconds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseconds_from_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/operations/operation.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, params, data)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mpredict_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_for_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitted_operation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/operations/operation.py\u001b[0m in \u001b[0;36mpredict_for_fit\u001b[0;34m(self, fitted_operation, data, params, output_mode)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \"\"\"\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitted_operation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_fit_stage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/operations/operation.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, fitted_operation, data, params, output_mode, is_fit_stage)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mtrained_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfitted_operation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 predict_data=data)\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/operations/evaluation/time_series.py\u001b[0m in \u001b[0;36mpredict_for_fit\u001b[0;34m(self, trained_operation, predict_data)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained_operation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_for_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/operations/evaluation/operation_implementations/data_operations/ts_transformations.py\u001b[0m in \u001b[0;36mtransform_for_fit\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     93\u001b[0m         new_target, new_idx = self._apply_transformation_for_fit(new_input_data, features,\n\u001b[0;32m---> 94\u001b[0;31m                                                                  target, forecast_length, old_idx)\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/operations/evaluation/operation_implementations/data_operations/ts_transformations.py\u001b[0m in \u001b[0;36m_apply_transformation_for_fit\u001b[0;34m(self, input_data, features, target, forecast_length, old_idx)\u001b[0m\n\u001b[1;32m    192\u001b[0m                     \u001b[0mall_transformed_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_transformed_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                     transformed_cols, new_target, new_idx)\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/operations/evaluation/operation_implementations/data_operations/ts_transformations.py\u001b[0m in \u001b[0;36mstack_by_type_fit\u001b[0;34m(self, input_data, all_features, all_target, all_idx, features, target, idx)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mstack_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctions_by_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstack_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/core/operations/evaluation/operation_implementations/data_operations/ts_transformations.py\u001b[0m in \u001b[0;36m_stack_multi_variable\u001b[0;34m(self, all_features, all_target, all_idx, features, target, idx)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mall_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mall_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1747 and the array at index 1 has size 1696",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ca39c369258e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/api/main.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target, predefined_model)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_composer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobtain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;31m# Final fit for obtained pipeline on full dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/api/api_utils/api_composer.py\u001b[0m in \u001b[0;36mobtain_model\u001b[0;34m(self, **common_dict)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mapi_params_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomposer_params_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuner_params_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_divide_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# Start composing - pipeline structure search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_fedot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_params_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomposer_params_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuner_params_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     def init_cache(self, use_pipelines_cache: bool, use_preprocessing_cache: bool,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/api/api_utils/api_composer.py\u001b[0m in \u001b[0;36mcompose_fedot_model\u001b[0;34m(self, api_params, composer_params, tuning_params)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 assumption_handler.fit_assumption_and_check_correctness(initial_assumption[0],\n\u001b[1;32m    201\u001b[0m                                                                         \u001b[0mpipelines_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipelines_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                                                                         preprocessing_cache=self.preprocessing_cache)\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         self.log.message(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/api/api_utils/assumptions/assumptions_handler.py\u001b[0m in \u001b[0;36mfit_assumption_and_check_correctness\u001b[0;34m(self, pipeline, pipelines_cache, preprocessing_cache)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_evaluating_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/practice/lib/python3.7/site-packages/fedot/api/api_utils/assumptions/assumptions_handler.py\u001b[0m in \u001b[0;36m_raise_evaluating_exception\u001b[0;34m(self, ex)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_failed_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madvice_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpropose_preset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mApiTime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Initial pipeline fit was failed due to: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1747 and the array at index 1 has size 1696. Check pipeline structure and the correctness of the data"
     ]
    }
   ],
   "source": [
    "pipeline = model.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-brother",
   "metadata": {},
   "source": [
    "As it works as a black-box, I don't know what is the underlying reason.\n",
    "\n",
    "The problem here is also that we couldn't simply take lagged values because of data specifics (we have the number of time serieses for different companies). That's why this framework suits only for individual forecasts for each of our companies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-upper",
   "metadata": {},
   "source": [
    "### LightAutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-yeast",
   "metadata": {},
   "source": [
    "It seems that there's no specific functionality for time series forecasting in this framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-poster",
   "metadata": {},
   "source": [
    "### AutoTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-bhutan",
   "metadata": {},
   "source": [
    "Frequency parameter infered from fake regressor, None specification is not allowed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "motivated-heavy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 cpus for n_jobs.\n"
     ]
    }
   ],
   "source": [
    "model = AutoTS(\n",
    "    forecast_length=10,\n",
    "    frequency='Q-DEC',\n",
    "    model_list = 'multivariate',\n",
    "    validation_method='backwards',\n",
    "    max_generations=3,\n",
    "    num_validations=3,\n",
    "    n_jobs='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "downtown-device",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred frequency is: Q-DEC\n"
     ]
    }
   ],
   "source": [
    "future_regressor_train2d, future_regressor_forecast2d = fake_regressor(\n",
    "    X_train,\n",
    "    forecast_length=10,\n",
    "    dimensions=X_train.shape[1],\n",
    "    drop_most_recent=model.drop_most_recent,\n",
    "    aggfunc=model.aggfunc,\n",
    "    verbose=model.verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "tested-friday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too many training validations for length of data provided, decreasing num_validations to 2\n",
      "Model Number: 1 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 1: GluonTS\n",
      "Model Number: 2 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 2: GluonTS\n",
      "Model Number: 3 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 3: GluonTS\n",
      "Model Number: 4 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 4: GluonTS\n",
      "Model Number: 5 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 5: GluonTS\n",
      "Model Number: 6 with model VAR in generation 0 of 3\n",
      "Template Eval Error: IndexError('index 0 is out of bounds for axis 0 with size 0') in model 6: VAR\n",
      "Model Number: 7 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('maxlags is too large for the number of observations and the number of equations. The largest model cannot be estimated.') in model 7: VAR\n",
      "Model Number: 8 with model VECM in generation 0 of 3\n",
      "Model Number: 9 with model VECM in generation 0 of 3\n",
      "Model Number: 10 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 11 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 11: GluonTS\n",
      "Model Number: 12 with model MultivariateRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 13 with model MultivariateRegression in generation 0 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 14 with model VECM in generation 0 of 3\n",
      "Model Number: 15 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 16 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 17 with model SectionalMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=20) out of bounds (16)') in model 17: SectionalMotif\n",
      "Model Number: 18 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 19 with model MultivariateRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 20 with model NVAR in generation 0 of 3\n",
      "Model Number: 21 with model RollingRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float32').\") in model 21: RollingRegression\n",
      "Model Number: 22 with model DynamicFactor in generation 0 of 3\n",
      "Model Number: 23 with model RollingRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float32').\") in model 23: RollingRegression\n",
      "Model Number: 24 with model Cassandra in generation 0 of 3\n",
      "Template Eval Error: Exception(\"unrecognized dates: Index([], dtype='object', name='date')\") in model 24: Cassandra\n",
      "Model Number: 25 with model VECM in generation 0 of 3\n",
      "Model Number: 26 with model DynamicFactor in generation 0 of 3\n",
      "Template Eval Error: AttributeError(\"'numpy.ndarray' object has no attribute 'values'\") in model 26: DynamicFactor\n",
      "Model Number: 27 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 27: GluonTS\n",
      "Model Number: 28 with model VARMAX in generation 0 of 3\n",
      "Model Number: 29 with model RollingRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Some value(s) of y are out of the valid range for family PoissonDistribution') in model 29: RollingRegression\n",
      "Model Number: 30 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 31 with model VAR in generation 0 of 3\n",
      "Model Number: 32 with model MultivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (32)') in model 32: MultivariateMotif\n",
      "Model Number: 33 with model NVAR in generation 0 of 3\n",
      "Model Number: 34 with model MultivariateRegression in generation 0 of 3\n",
      "Model Number: 35 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 36 with model DynamicFactorMQ in generation 0 of 3\n",
      "Template Eval Error: ValueError('Number of factors (4) cannot be greater than the number of monthly endogenous variables (2).') in model 36: DynamicFactorMQ\n",
      "Model Number: 37 with model PytorchForecasting in generation 0 of 3\n",
      "Template Eval Error: ImportError('pytorch, pytorch lighting, or pytorch-forecasting not present') in model 37: PytorchForecasting\n",
      "Model Number: 38 with model RRVAR in generation 0 of 3\n",
      "Model Number: 39 with model MAR in generation 0 of 3\n",
      "Model Number: 40 with model TMF in generation 0 of 3\n",
      "Template Eval Error: ValueError('Model TMF returned NaN for one or more series. fail_on_forecast_nan=True') in model 40: TMF\n",
      "Model Number: 41 with model LATC in generation 0 of 3\n",
      "Template Eval Error: ValueError('negative dimensions are not allowed') in model 41: LATC\n",
      "Model Number: 42 with model Cassandra in generation 0 of 3\n",
      "Dropping zero variance feature columns Index(['seasonality7_6'], dtype='object')\n",
      "Dropping multi-colinear feature columns Index(['seasonality365.25_7', 'seasonality365.25_8', 'seasonality365.25_9',\n",
      "       'seasonality365.25_10', 'seasonality365.25_11', 'seasonality365.25_12',\n",
      "       'seasonality365.25_13', 'seasonality365.25_14', 'seasonality365.25_15',\n",
      "       'seasonality365.25_16', 'seasonality365.25_17', 'seasonality365.25_18',\n",
      "       'seasonality365.25_19', 'randomwalk_0', 'randomwalk_1', 'randomwalk_2',\n",
      "       'randomwalk_3', 'randomwalk_4', 'randomwalk_5', 'randomwalk_6',\n",
      "       'randomwalk_7', 'randomwalk_8', 'randomwalk_9', 'rolling_trend_0',\n",
      "       'rolling_trend_1'],\n",
      "      dtype='object')\n",
      "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 42: Cassandra\n",
      "Model Number: 43 with model PytorchForecasting in generation 0 of 3\n",
      "Template Eval Error: ImportError('pytorch, pytorch lighting, or pytorch-forecasting not present') in model 43: PytorchForecasting\n",
      "Model Number: 44 with model Cassandra in generation 0 of 3\n",
      "Dropping zero variance feature columns Index(['weekdayofmonth_1', 'weekdayofmonth_2', 'weekdayofmonth_3',\n",
      "       'weekdayofmonth_4', 'weekdayofmonth_5'],\n",
      "      dtype='object')\n",
      "Dropping multi-colinear feature columns Index(['seasonalitycommonfourier_16', 'seasonalitycommonfourier_17',\n",
      "       'seasonalitycommonfourier_18', 'seasonalitycommonfourier_19',\n",
      "       'seasonalitycommonfourier_20', 'seasonalitycommonfourier_21',\n",
      "       'seasonalitycommonfourier_22', 'seasonalitycommonfourier_23',\n",
      "       'seasonalitycommonfourier_24', 'seasonalitycommonfourier_25',\n",
      "       'randnorm_0', 'randnorm_1', 'randnorm_2', 'randnorm_3'],\n",
      "      dtype='object')\n",
      "Template Eval Error: ValueError('kth(=9) out of bounds (4)') in model 44: Cassandra\n",
      "Model Number: 45 with model LATC in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/models/cassandra.py:473: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  slope * self.t_train[..., None] + intercept,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 46 with model TMF in generation 0 of 3\n",
      "Template Eval Error: ValueError('Model TMF returned NaN for one or more series. fail_on_forecast_nan=True') in model 46: TMF\n",
      "Model Number: 47 with model SectionalMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=5) out of bounds (1)') in model 47: SectionalMotif\n",
      "Model Number: 48 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 49 with model LATC in generation 0 of 3\n",
      "Model Number: 50 with model LATC in generation 0 of 3\n",
      "Model Number: 51 with model TMF in generation 0 of 3\n",
      "Template Eval Error: ValueError('Model TMF returned NaN for one or more series. fail_on_forecast_nan=True') in model 51: TMF\n",
      "Model Number: 52 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 53 with model SectionalMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (8)') in model 53: SectionalMotif\n",
      "Model Number: 54 with model VARMAX in generation 0 of 3\n",
      "Model Number: 55 with model PytorchForecasting in generation 0 of 3\n",
      "Template Eval Error: ImportError('pytorch, pytorch lighting, or pytorch-forecasting not present') in model 55: PytorchForecasting\n",
      "Model Number: 56 with model RRVAR in generation 0 of 3\n",
      "Model Number: 57 with model RollingRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 57: RollingRegression\n",
      "Model Number: 58 with model SectionalMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (16)') in model 58: SectionalMotif\n",
      "Model Number: 59 with model LATC in generation 0 of 3\n",
      "Template Eval Error: ValueError('LATC cannot accept any arrays that are all 0') in model 59: LATC\n",
      "Model Number: 60 with model VAR in generation 0 of 3\n",
      "Template Eval Error: IndexError('index 0 is out of bounds for axis 0 with size 0') in model 60: VAR\n",
      "Model Number: 61 with model TMF in generation 0 of 3\n",
      "Template Eval Error: ValueError('Model TMF returned NaN for one or more series. fail_on_forecast_nan=True') in model 61: TMF\n",
      "Model Number: 62 with model SectionalMotif in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 63 with model Cassandra in generation 0 of 3\n",
      "Dropping zero variance feature columns Index(['month_1', 'month_2', 'month_4', 'month_5', 'month_7', 'month_8',\n",
      "       'month_10', 'month_11', 'weekdayofmonth_1', 'weekdayofmonth_2',\n",
      "       'weekdayofmonth_3', 'weekdayofmonth_4', 'weekdayofmonth_5'],\n",
      "      dtype='object')\n",
      "Dropping multi-colinear feature columns Index(['randomwalk_8', 'randomwalk_9'], dtype='object')\n",
      "Template Eval Error: ValueError('operands could not be broadcast together with shapes (114,2) (124,2) ') in model 63: Cassandra\n",
      "Model Number: 64 with model MultivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (32)') in model 64: MultivariateMotif\n",
      "Model Number: 65 with model SectionalMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('XA and XB must have the same number of columns (i.e. feature dimension.)') in model 65: SectionalMotif\n",
      "Model Number: 66 with model DynamicFactorMQ in generation 0 of 3\n",
      "Template Eval Error: ValueError('Number of factors (4) cannot be greater than the number of monthly endogenous variables (2).') in model 66: DynamicFactorMQ\n",
      "Model Number: 67 with model VARMAX in generation 0 of 3\n",
      "Model Number: 68 with model VECM in generation 0 of 3\n",
      "Model Number: 69 with model VARMAX in generation 0 of 3\n",
      "Model Number: 70 with model Cassandra in generation 0 of 3\n",
      "Dropping zero variance feature columns Index(['seasonality7_6'], dtype='object')\n",
      "Dropping multi-colinear feature columns Index(['seasonality365.25_5', 'seasonality365.25_6', 'seasonality365.25_7',\n",
      "       'seasonality365.25_8', 'seasonality365.25_9', 'seasonality365.25_10',\n",
      "       'seasonality365.25_11', 'seasonality365.25_12', 'seasonality365.25_13',\n",
      "       'seasonality365.25_14', 'seasonality365.25_15', 'seasonality365.25_16',\n",
      "       'seasonality365.25_17', 'seasonality365.25_18', 'seasonality365.25_19',\n",
      "       'randomwalk_0', 'randomwalk_1', 'randomwalk_2', 'randomwalk_3',\n",
      "       'randomwalk_4', 'randomwalk_5', 'randomwalk_6', 'randomwalk_7',\n",
      "       'randomwalk_8', 'randomwalk_9'],\n",
      "      dtype='object')\n",
      "Template Eval Error: ValueError('operands could not be broadcast together with shapes (114,2) (124,2) ') in model 70: Cassandra\n",
      "Model Number: 71 with model RollingRegression in generation 0 of 3\n",
      "Model Number: 72 with model Cassandra in generation 0 of 3\n",
      "Dropping zero variance feature columns Index(['weekdayofmonth_1', 'weekdayofmonth_2', 'weekdayofmonth_3',\n",
      "       'weekdayofmonth_4', 'weekdayofmonth_5'],\n",
      "      dtype='object')\n",
      "Dropping multi-colinear feature columns Index(['seasonalitycommonfourier_25', 'randomwalk_0', 'randomwalk_1',\n",
      "       'randomwalk_2', 'randomwalk_3', 'randomwalk_4', 'randomwalk_5',\n",
      "       'randomwalk_6', 'randomwalk_7', 'randomwalk_8', 'randomwalk_9'],\n",
      "      dtype='object')\n",
      "Model Number: 73 with model LATC in generation 0 of 3\n",
      "Template Eval Error: ValueError('LATC cannot accept any arrays that are all 0') in model 73: LATC\n",
      "Model Number: 74 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 75 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 76 with model MultivariateRegression in generation 0 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 77 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 78 with model VARMAX in generation 0 of 3\n",
      "Model Number: 79 with model MultivariateRegression in generation 0 of 3\n",
      "Model Number: 80 with model Cassandra in generation 0 of 3\n",
      "Dropping multi-colinear feature columns Index(['seasonality365.25_10', 'seasonality365.25_11', 'seasonality365.25_12',\n",
      "       'seasonality365.25_13', 'seasonality365.25_14', 'seasonality365.25_15',\n",
      "       'seasonality365.25_16', 'seasonality365.25_17', 'seasonality365.25_18',\n",
      "       'seasonality365.25_19', 'randnorm_0', 'randnorm_1', 'randnorm_2',\n",
      "       'randnorm_3'],\n",
      "      dtype='object')\n",
      "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 80: Cassandra\n",
      "Model Number: 81 with model DynamicFactor in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 81: DynamicFactor\n",
      "Model Number: 82 with model MAR in generation 0 of 3\n",
      "Model Number: 83 with model VECM in generation 0 of 3\n",
      "Model Number: 84 with model RRVAR in generation 0 of 3\n",
      "Model Number: 85 with model VECM in generation 0 of 3\n",
      "Model Number: 86 with model MAR in generation 0 of 3\n",
      "Model Number: 87 with model DynamicFactorMQ in generation 0 of 3\n",
      "Template Eval Error: ValueError('Number of factors (3) cannot be greater than the number of monthly endogenous variables (2).') in model 87: DynamicFactorMQ\n",
      "Model Number: 88 with model VAR in generation 0 of 3\n",
      "Template Eval Error: IndexError('index 0 is out of bounds for axis 0 with size 0') in model 88: VAR\n",
      "Model Number: 89 with model DynamicFactor in generation 0 of 3\n",
      "Model Number: 90 with model Cassandra in generation 0 of 3\n",
      "Template Eval Error: TypeError('can only concatenate str (not \"int\") to str') in model 90: Cassandra\n",
      "Model Number: 91 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 91: GluonTS\n",
      "Model Number: 92 with model LATC in generation 0 of 3\n",
      "Model Number: 93 with model RollingRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 93: RollingRegression\n",
      "Model Number: 94 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 95 with model RRVAR in generation 0 of 3\n",
      "Model Number: 96 with model MultivariateRegression in generation 0 of 3\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 97 with model VARMAX in generation 0 of 3\n",
      "Model Number: 98 with model DynamicFactorMQ in generation 0 of 3\n",
      "Template Eval Error: ValueError('Number of factors (4) cannot be greater than the number of monthly endogenous variables (2).') in model 98: DynamicFactorMQ\n",
      "Model Number: 99 with model NVAR in generation 0 of 3\n",
      "Model Number: 100 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('maxlags is too large for the number of observations and the number of equations. The largest model cannot be estimated.') in model 100: VAR\n",
      "Model Number: 101 with model MAR in generation 0 of 3\n",
      "Model Number: 102 with model MultivariateRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 102: MultivariateRegression\n",
      "Model Number: 103 with model PytorchForecasting in generation 0 of 3\n",
      "Template Eval Error: ImportError('pytorch, pytorch lighting, or pytorch-forecasting not present') in model 103: PytorchForecasting\n",
      "Model Number: 104 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 105 with model Cassandra in generation 0 of 3\n",
      "Dropping zero variance feature columns Index(['month_1', 'month_2', 'month_4', 'month_5', 'month_7', 'month_8',\n",
      "       'month_10', 'month_11', 'weekdayofmonth_1', 'weekdayofmonth_2',\n",
      "       'weekdayofmonth_3', 'weekdayofmonth_4', 'weekdayofmonth_5'],\n",
      "      dtype='object')\n",
      "Dropping multi-colinear feature columns Index(['randnorm_2', 'randnorm_3'], dtype='object')\n",
      "Template Eval Error: ValueError('operands could not be broadcast together with shapes (114,2) (124,2) ') in model 105: Cassandra\n",
      "Model Number: 106 with model DynamicFactor in generation 0 of 3\n",
      "Template Eval Error: AttributeError(\"'numpy.ndarray' object has no attribute 'values'\") in model 106: DynamicFactor\n",
      "Model Number: 107 with model NVAR in generation 0 of 3\n",
      "Model Number: 108 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('maxlags is too large for the number of observations and the number of equations. The largest model cannot be estimated.') in model 108: VAR\n",
      "Model Number: 109 with model SectionalMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=20) out of bounds (16)') in model 109: SectionalMotif\n",
      "Model Number: 110 with model VECM in generation 0 of 3\n",
      "Model Number: 111 with model NVAR in generation 0 of 3\n",
      "Model Number: 112 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 113 with model DynamicFactor in generation 0 of 3\n",
      "Template Eval Error: ValueError('Number of factors must be less than the number of endogenous variables.') in model 113: DynamicFactor\n",
      "Model Number: 114 with model MAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Shape of passed values is (7, 2), indices imply (10, 2)') in model 114: MAR\n",
      "New Generation: 1 of 3\n",
      "Model Number: 115 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 116 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 117 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 118 with model VARMAX in generation 1 of 3\n",
      "Model Number: 119 with model RRVAR in generation 1 of 3\n",
      "Model Number: 120 with model WindowRegression in generation 1 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 120: WindowRegression\n",
      "Model Number: 121 with model VARMAX in generation 1 of 3\n",
      "Model Number: 122 with model VECM in generation 1 of 3\n",
      "Model Number: 123 with model LATC in generation 1 of 3\n",
      "Model Number: 124 with model VARMAX in generation 1 of 3\n",
      "Model Number: 125 with model VARMAX in generation 1 of 3\n",
      "Model Number: 126 with model VECM in generation 1 of 3\n",
      "Model Number: 127 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 128 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 129 with model MAR in generation 1 of 3\n",
      "Model Number: 130 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 131 with model LATC in generation 1 of 3\n",
      "Template Eval Error: ValueError('LATC cannot accept any arrays that are all 0') in model 131: LATC\n",
      "Model Number: 132 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 133 with model MultivariateRegression in generation 1 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 134 with model LATC in generation 1 of 3\n",
      "Model Number: 135 with model RRVAR in generation 1 of 3\n",
      "Model Number: 136 with model VARMAX in generation 1 of 3\n",
      "Model Number: 137 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 138 with model RRVAR in generation 1 of 3\n",
      "Model Number: 139 with model MultivariateMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (24)') in model 139: MultivariateMotif\n",
      "Model Number: 140 with model NVAR in generation 1 of 3\n",
      "Model Number: 141 with model DynamicFactor in generation 1 of 3\n",
      "Template Eval Error: ZeroDivisionError('integer division or modulo by zero') in model 141: DynamicFactor\n",
      "Model Number: 142 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 143 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 144 with model SectionalMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('zero-size array to reduction operation fmax which has no identity') in model 144: SectionalMotif\n",
      "Model Number: 145 with model VECM in generation 1 of 3\n",
      "Model Number: 146 with model RRVAR in generation 1 of 3\n",
      "Model Number: 147 with model VECM in generation 1 of 3\n",
      "Model Number: 148 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 149 with model NVAR in generation 1 of 3\n",
      "Model Number: 150 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 151 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 152 with model DynamicFactor in generation 1 of 3\n",
      "Template Eval Error: ZeroDivisionError('integer division or modulo by zero') in model 152: DynamicFactor\n",
      "Model Number: 153 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 154 with model Cassandra in generation 1 of 3\n",
      "No anomalies detected.\n",
      "Dropping zero variance feature columns Index(['seasonality7_6'], dtype='object')\n",
      "Dropping multi-colinear feature columns Index(['seasonality365.25_5', 'seasonality365.25_6', 'seasonality365.25_7',\n",
      "       'seasonality365.25_8', 'seasonality365.25_9', 'seasonality365.25_10',\n",
      "       'seasonality365.25_11', 'seasonality365.25_12', 'seasonality365.25_13',\n",
      "       'seasonality365.25_14', 'seasonality365.25_15', 'seasonality365.25_16',\n",
      "       'seasonality365.25_17', 'seasonality365.25_18', 'seasonality365.25_19',\n",
      "       'randomwalk_0', 'randomwalk_1', 'randomwalk_2', 'randomwalk_3',\n",
      "       'randomwalk_4', 'randomwalk_5', 'randomwalk_6', 'randomwalk_7',\n",
      "       'randomwalk_8', 'randomwalk_9'],\n",
      "      dtype='object')\n",
      "Model Number: 155 with model Cassandra in generation 1 of 3\n",
      "No anomalies detected.\n",
      "Template Eval Error: TypeError('can only concatenate str (not \"int\") to str') in model 155: Cassandra\n",
      "Model Number: 156 with model VECM in generation 1 of 3\n",
      "Model Number: 157 with model LATC in generation 1 of 3\n",
      "Model Number: 158 with model VECM in generation 1 of 3\n",
      "Model Number: 159 with model RRVAR in generation 1 of 3\n",
      "Model Number: 160 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 161 with model LATC in generation 1 of 3\n",
      "Model Number: 162 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 163 with model LATC in generation 1 of 3\n",
      "Template Eval Error: ValueError('negative dimensions are not allowed') in model 163: LATC\n",
      "Model Number: 164 with model DynamicFactor in generation 1 of 3\n",
      "Model Number: 165 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 166 with model RRVAR in generation 1 of 3\n",
      "Model Number: 167 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 168 with model NVAR in generation 1 of 3\n",
      "Model Number: 169 with model VECM in generation 1 of 3\n",
      "Model Number: 170 with model VARMAX in generation 1 of 3\n",
      "Model Number: 171 with model VECM in generation 1 of 3\n",
      "Model Number: 172 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 173 with model VARMAX in generation 1 of 3\n",
      "Model Number: 174 with model VARMAX in generation 1 of 3\n",
      "Model Number: 175 with model VARMAX in generation 1 of 3\n",
      "Model Number: 176 with model VARMAX in generation 1 of 3\n",
      "Model Number: 177 with model VECM in generation 1 of 3\n",
      "Model Number: 178 with model MultivariateRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 179 with model DynamicFactor in generation 1 of 3\n",
      "Model Number: 180 with model RRVAR in generation 1 of 3\n",
      "Model Number: 181 with model LATC in generation 1 of 3\n",
      "Model Number: 182 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 183 with model MultivariateRegression in generation 1 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 184 with model Cassandra in generation 1 of 3\n",
      "Template Eval Error: TypeError('can only concatenate str (not \"int\") to str') in model 184: Cassandra\n",
      "Model Number: 185 with model LATC in generation 1 of 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 186 with model VARMAX in generation 1 of 3\n",
      "Model Number: 187 with model MAR in generation 1 of 3\n",
      "Model Number: 188 with model RRVAR in generation 1 of 3\n",
      "Model Number: 189 with model DynamicFactor in generation 1 of 3\n",
      "Template Eval Error: ValueError('Number of factors must be less than the number of endogenous variables.') in model 189: DynamicFactor\n",
      "Model Number: 190 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 191 with model VAR in generation 1 of 3\n",
      "Model Number: 192 with model MAR in generation 1 of 3\n",
      "Model Number: 193 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 194 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 195 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 196 with model VARMAX in generation 1 of 3\n",
      "Model Number: 197 with model VECM in generation 1 of 3\n",
      "Model Number: 198 with model MultivariateRegression in generation 1 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 199 with model VECM in generation 1 of 3\n",
      "Model Number: 200 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 201 with model VARMAX in generation 1 of 3\n",
      "Template Eval Error: LinAlgError('1-dimensional array given. Array must be two-dimensional') in model 201: VARMAX\n",
      "Model Number: 202 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 203 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 204 with model WindowRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Generation: 2 of 3\n",
      "Model Number: 205 with model NVAR in generation 2 of 3\n",
      "Template Eval Error: ValueError('Model NVAR returned NaN for one or more series. fail_on_forecast_nan=True') in model 205: NVAR\n",
      "Model Number: 206 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 207 with model VECM in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 207: VECM\n",
      "Model Number: 208 with model VAR in generation 2 of 3\n",
      "Model Number: 209 with model Cassandra in generation 2 of 3\n",
      "Template Eval Error: TypeError('can only concatenate str (not \"int\") to str') in model 209: Cassandra\n",
      "Model Number: 210 with model MultivariateRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/models/cassandra.py:473: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  slope * self.t_train[..., None] + intercept,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 211 with model RRVAR in generation 2 of 3\n",
      "Model Number: 212 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 213 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 214 with model VECM in generation 2 of 3\n",
      "Model Number: 215 with model Cassandra in generation 2 of 3\n",
      "Template Eval Error: TypeError('can only concatenate str (not \"int\") to str') in model 215: Cassandra\n",
      "Model Number: 216 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 217 with model RRVAR in generation 2 of 3\n",
      "Model Number: 218 with model WindowRegression in generation 2 of 3\n",
      "Template Eval Error: ValueError('Some value(s) of y are out of the valid range for family PoissonDistribution') in model 218: WindowRegression\n",
      "Model Number: 219 with model VECM in generation 2 of 3\n",
      "Model Number: 220 with model VARMAX in generation 2 of 3\n",
      "Model Number: 221 with model RRVAR in generation 2 of 3\n",
      "Model Number: 222 with model LATC in generation 2 of 3\n",
      "Model Number: 223 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 224 with model VECM in generation 2 of 3\n",
      "Template Eval Error: LinAlgError('Singular matrix') in model 224: VECM\n",
      "Model Number: 225 with model VARMAX in generation 2 of 3\n",
      "Model Number: 226 with model SectionalMotif in generation 2 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (2)') in model 226: SectionalMotif\n",
      "Model Number: 227 with model RRVAR in generation 2 of 3\n",
      "Model Number: 228 with model VECM in generation 2 of 3\n",
      "Model Number: 229 with model DynamicFactor in generation 2 of 3\n",
      "Model Number: 230 with model RRVAR in generation 2 of 3\n",
      "Model Number: 231 with model RRVAR in generation 2 of 3\n",
      "Model Number: 232 with model DynamicFactor in generation 2 of 3\n",
      "Template Eval Error: ValueError('Number of factors must be less than the number of endogenous variables.') in model 232: DynamicFactor\n",
      "Model Number: 233 with model Cassandra in generation 2 of 3\n",
      "Template Eval Error: TypeError('can only concatenate str (not \"int\") to str') in model 233: Cassandra\n",
      "Model Number: 234 with model MAR in generation 2 of 3\n",
      "Template Eval Error: ValueError('Shape of passed values is (7, 2), indices imply (10, 2)') in model 234: MAR\n",
      "Model Number: 235 with model VAR in generation 2 of 3\n",
      "Template Eval Error: ValueError('maxlags is too large for the number of observations and the number of equations. The largest model cannot be estimated.') in model 235: VAR\n",
      "Model Number: 236 with model VARMAX in generation 2 of 3\n",
      "Model Number: 237 with model NVAR in generation 2 of 3\n",
      "Model Number: 238 with model VARMAX in generation 2 of 3\n",
      "Model Number: 239 with model Cassandra in generation 2 of 3\n",
      "Dropping multi-colinear feature columns Index(['seasonality365.25_16', 'seasonality365.25_17', 'seasonality365.25_18',\n",
      "       'seasonality365.25_19', 'randomwalk_0', 'randomwalk_1', 'randomwalk_2',\n",
      "       'randomwalk_3', 'randomwalk_4', 'randomwalk_5', 'randomwalk_6',\n",
      "       'randomwalk_7', 'randomwalk_8', 'randomwalk_9'],\n",
      "      dtype='object')\n",
      "Template Eval Error: ValueError('operands could not be broadcast together with shapes (114,2) (124,2) ') in model 239: Cassandra\n",
      "Model Number: 240 with model LATC in generation 2 of 3\n",
      "Model Number: 241 with model VAR in generation 2 of 3\n",
      "Model Number: 242 with model RollingRegression in generation 2 of 3\n",
      "Model Number: 243 with model VECM in generation 2 of 3\n",
      "Model Number: 244 with model VARMAX in generation 2 of 3\n",
      "Model Number: 245 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 246 with model VARMAX in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 246: VARMAX\n",
      "Model Number: 247 with model VECM in generation 2 of 3\n",
      "Model Number: 248 with model MAR in generation 2 of 3\n",
      "Template Eval Error: ValueError('Shape of passed values is (7, 2), indices imply (10, 2)') in model 248: MAR\n",
      "Model Number: 249 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 250 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 251 with model RRVAR in generation 2 of 3\n",
      "Model Number: 252 with model NVAR in generation 2 of 3\n",
      "Model Number: 253 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 254 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 255 with model RRVAR in generation 2 of 3\n",
      "Template Eval Error: LinAlgError('Array must not contain infs or NaNs') in model 255: RRVAR\n",
      "Model Number: 256 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 257 with model VARMAX in generation 2 of 3\n",
      "Model Number: 258 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 259 with model NVAR in generation 2 of 3\n",
      "Model Number: 260 with model VARMAX in generation 2 of 3\n",
      "Model Number: 261 with model MAR in generation 2 of 3\n",
      "Model Number: 262 with model DynamicFactor in generation 2 of 3\n",
      "Model Number: 263 with model VECM in generation 2 of 3\n",
      "Model Number: 264 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 265 with model VARMAX in generation 2 of 3\n",
      "Model Number: 266 with model RRVAR in generation 2 of 3\n",
      "Model Number: 267 with model LATC in generation 2 of 3\n",
      "Template Eval Error: ValueError('LATC cannot accept any arrays that are all 0') in model 267: LATC\n",
      "Model Number: 268 with model LATC in generation 2 of 3\n",
      "Model Number: 269 with model VECM in generation 2 of 3\n",
      "Model Number: 270 with model VARMAX in generation 2 of 3\n",
      "Model Number: 271 with model DynamicFactor in generation 2 of 3\n",
      "Model Number: 272 with model LATC in generation 2 of 3\n",
      "Model Number: 273 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 274 with model RRVAR in generation 2 of 3\n",
      "Model Number: 275 with model DynamicFactor in generation 2 of 3\n",
      "Template Eval Error: ValueError('Number of factors must be less than the number of endogenous variables.') in model 275: DynamicFactor\n",
      "Model Number: 276 with model DynamicFactor in generation 2 of 3\n",
      "Template Eval Error: MissingDataError('exog contains inf or nans') in model 276: DynamicFactor\n",
      "Model Number: 277 with model RRVAR in generation 2 of 3\n",
      "Model Number: 278 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 279 with model VARMAX in generation 2 of 3\n",
      "Model Number: 280 with model VAR in generation 2 of 3\n",
      "Template Eval Error: ValueError('maxlags is too large for the number of observations and the number of equations. The largest model cannot be estimated.') in model 280: VAR\n",
      "Model Number: 281 with model VECM in generation 2 of 3\n",
      "Model Number: 282 with model LATC in generation 2 of 3\n",
      "Model Number: 283 with model MAR in generation 2 of 3\n",
      "Model Number: 284 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 285 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 286 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 287 with model LATC in generation 2 of 3\n",
      "Template Eval Error: ValueError('LATC cannot accept any arrays that are all 0') in model 287: LATC\n",
      "Model Number: 288 with model RRVAR in generation 2 of 3\n",
      "Model Number: 289 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 290 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 291 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 292 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 293 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 294 with model LATC in generation 2 of 3\n",
      "Template Eval Error: ValueError('LATC cannot accept any arrays that are all 0') in model 294: LATC\n",
      "New Generation: 3 of 3\n",
      "Model Number: 295 with model DynamicFactor in generation 3 of 3\n",
      "Model Number: 296 with model DynamicFactor in generation 3 of 3\n",
      "Model Number: 297 with model VECM in generation 3 of 3\n",
      "Model Number: 298 with model RRVAR in generation 3 of 3\n",
      "Model Number: 299 with model NVAR in generation 3 of 3\n",
      "Template Eval Error: ValueError('Model NVAR returned NaN for one or more series. fail_on_forecast_nan=True') in model 299: NVAR\n",
      "Model Number: 300 with model VECM in generation 3 of 3\n",
      "No anomalies detected.\n",
      "Model Number: 301 with model NVAR in generation 3 of 3\n",
      "Model Number: 302 with model VARMAX in generation 3 of 3\n",
      "Model Number: 303 with model DynamicFactor in generation 3 of 3\n",
      "Model Number: 304 with model VAR in generation 3 of 3\n",
      "Template Eval Error: IndexError('index 0 is out of bounds for axis 0 with size 0') in model 304: VAR\n",
      "Model Number: 305 with model VARMAX in generation 3 of 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 306 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 307 with model VECM in generation 3 of 3\n",
      "Model Number: 308 with model VARMAX in generation 3 of 3\n",
      "Model Number: 309 with model VARMAX in generation 3 of 3\n",
      "Model Number: 310 with model VAR in generation 3 of 3\n",
      "Model Number: 311 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 312 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 313 with model VECM in generation 3 of 3\n",
      "Model Number: 314 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 315 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 316 with model VARMAX in generation 3 of 3\n",
      "Model Number: 317 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 318 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 319 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 320 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 321 with model VECM in generation 3 of 3\n",
      "Model Number: 322 with model VARMAX in generation 3 of 3\n",
      "Model Number: 323 with model Cassandra in generation 3 of 3\n",
      "Template Eval Error: TypeError('can only concatenate str (not \"int\") to str') in model 323: Cassandra\n",
      "Model Number: 324 with model VARMAX in generation 3 of 3\n",
      "Model Number: 325 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 326 with model VECM in generation 3 of 3\n",
      "Model Number: 327 with model RRVAR in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 327: RRVAR\n",
      "Model Number: 328 with model RRVAR in generation 3 of 3\n",
      "Model Number: 329 with model DynamicFactor in generation 3 of 3\n",
      "Model Number: 330 with model NVAR in generation 3 of 3\n",
      "Model Number: 331 with model VARMAX in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 331: VARMAX\n",
      "Model Number: 332 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 333 with model MAR in generation 3 of 3\n",
      "Model Number: 334 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 335 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 336 with model VARMAX in generation 3 of 3\n",
      "Model Number: 337 with model LATC in generation 3 of 3\n",
      "Model Number: 338 with model RRVAR in generation 3 of 3\n",
      "Model Number: 339 with model LATC in generation 3 of 3\n",
      "Model Number: 340 with model VARMAX in generation 3 of 3\n",
      "Template Eval Error: LinAlgError('Matrix is not positive definite') in model 340: VARMAX\n",
      "Model Number: 341 with model VAR in generation 3 of 3\n",
      "Model Number: 342 with model MultivariateRegression in generation 3 of 3\n",
      "Template Eval Error: ValueError('`min_samples` may not be larger than number of samples: n_samples = 68.') in model 342: MultivariateRegression\n",
      "Model Number: 343 with model WindowRegression in generation 3 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 343: WindowRegression\n",
      "Model Number: 344 with model LATC in generation 3 of 3\n",
      "Model Number: 345 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 346 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 347 with model VARMAX in generation 3 of 3\n",
      "Model Number: 348 with model LATC in generation 3 of 3\n",
      "Model Number: 349 with model VARMAX in generation 3 of 3\n",
      "Model Number: 350 with model VAR in generation 3 of 3\n",
      "Model Number: 351 with model MAR in generation 3 of 3\n",
      "Model Number: 352 with model VECM in generation 3 of 3\n",
      "Model Number: 353 with model VAR in generation 3 of 3\n",
      "Model Number: 354 with model VECM in generation 3 of 3\n",
      "Model Number: 355 with model VECM in generation 3 of 3\n",
      "Model Number: 356 with model DynamicFactor in generation 3 of 3\n",
      "Model Number: 357 with model Cassandra in generation 3 of 3\n",
      "Dropping zero variance feature columns Index(['weekdayofmonth_1', 'weekdayofmonth_2', 'weekdayofmonth_3',\n",
      "       'weekdayofmonth_4', 'weekdayofmonth_5'],\n",
      "      dtype='object')\n",
      "Dropping multi-colinear feature columns Index(['seasonalitycommonfourier_25', 'randomwalk_0', 'randomwalk_1',\n",
      "       'randomwalk_2', 'randomwalk_3', 'randomwalk_4', 'randomwalk_5',\n",
      "       'randomwalk_6', 'randomwalk_7', 'randomwalk_8', 'randomwalk_9'],\n",
      "      dtype='object')\n",
      "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 357: Cassandra\n",
      "Model Number: 358 with model DynamicFactor in generation 3 of 3\n",
      "Model Number: 359 with model RRVAR in generation 3 of 3\n",
      "Model Number: 360 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 361 with model RollingRegression in generation 3 of 3\n",
      "Model Number: 362 with model VARMAX in generation 3 of 3\n",
      "Model Number: 363 with model VAR in generation 3 of 3\n",
      "Template Eval Error: IndexError('index 0 is out of bounds for axis 0 with size 0') in model 363: VAR\n",
      "Model Number: 364 with model VECM in generation 3 of 3\n",
      "Model Number: 365 with model LATC in generation 3 of 3\n",
      "Model Number: 366 with model RRVAR in generation 3 of 3\n",
      "Model Number: 367 with model RRVAR in generation 3 of 3\n",
      "Model Number: 368 with model RRVAR in generation 3 of 3\n",
      "Model Number: 369 with model RRVAR in generation 3 of 3\n",
      "Model Number: 370 with model RRVAR in generation 3 of 3\n",
      "Model Number: 371 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 372 with model LATC in generation 3 of 3\n",
      "Template Eval Error: ValueError('LATC cannot accept any arrays that are all 0') in model 372: LATC\n",
      "Model Number: 373 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 374 with model VECM in generation 3 of 3\n",
      "Model Number: 375 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 376 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 377 with model SectionalMotif in generation 3 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (16)') in model 377: SectionalMotif\n",
      "Model Number: 378 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 379 with model MAR in generation 3 of 3\n",
      "Model Number: 380 with model NVAR in generation 3 of 3\n",
      "Model Number: 381 with model VECM in generation 3 of 3\n",
      "Model Number: 382 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 383 with model MAR in generation 3 of 3\n",
      "Template Eval Error: ValueError('Shape of passed values is (7, 2), indices imply (10, 2)') in model 383: MAR\n",
      "Model Number: 384 with model VARMAX in generation 3 of 3\n",
      "Model Number: 385 with model Ensemble in generation 4 of Ensembles\n",
      "Model Number: 386 with model Ensemble in generation 4 of Ensembles\n",
      "Model Number: 387 with model Ensemble in generation 4 of Ensembles\n",
      "Model Number: 388 with model Ensemble in generation 4 of Ensembles\n",
      "Model Number: 389 with model Ensemble in generation 4 of Ensembles\n",
      "Model Number: 390 with model Ensemble in generation 4 of Ensembles\n",
      "Model Number: 391 with model Ensemble in generation 4 of Ensembles\n",
      "Model Number: 392 with model Ensemble in generation 4 of Ensembles\n",
      "Model Number: 393 with model Ensemble in generation 4 of Ensembles\n",
      "Model Number: 394 with model Ensemble in generation 4 of Ensembles\n",
      "Validation Round: 1\n",
      "Model Number: 1 of 59 with model Ensemble for Validation 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/tools/transform.py\", line 3602, in _fit\n",
      "    df = self.transformers[i].fit_transform(df)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/tools/transform.py\", line 2577, in fit_transform\n",
      "    self.fit(df)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/tools/transform.py\", line 2512, in fit\n",
      "    self.center = self.find_centerpoint(df, self.rows, self.lag)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/tools/transform.py\", line 2520, in find_centerpoint\n",
      "    center = df.iloc[-lag, :]\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/pandas/core/indexing.py\", line 889, in __getitem__\n",
      "    return self._getitem_tuple(key)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/pandas/core/indexing.py\", line 1450, in _getitem_tuple\n",
      "    self._has_valid_tuple(tup)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/pandas/core/indexing.py\", line 723, in _has_valid_tuple\n",
      "    self._validate_key(k, i)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/pandas/core/indexing.py\", line 1358, in _validate_key\n",
      "    self._validate_integer(key, axis)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/pandas/core/indexing.py\", line 1444, in _validate_integer\n",
      "    raise IndexError(\"single positional indexer is out-of-bounds\")\n",
      "IndexError: single positional indexer is out-of-bounds\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 1112, in model_forecast\n",
      "    model_count=model_count,\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 1198, in model_forecast\n",
      "    model_count=model_count,\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 681, in ModelPrediction\n",
      "    df_train_transformed = transformer_object._fit(df_train)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/tools/transform.py\", line 3614, in _fit\n",
      "    ) from e\n",
      "Exception: Transformer AlignLastValue failed on fit\n",
      "\n",
      "FAILED: Ensemble Dist component 3 of 2 MultivariateMotif with error: Exception('Transformer AlignLastValue failed on fit')\n",
      "Template Eval Error: ValueError(\"'3ff89c07663fe3bfe89a7be379c930d9' is not in list\") in model 1: Ensemble\n",
      "Model Number: 2 of 59 with model Ensemble for Validation 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 1112, in model_forecast\n",
      "    model_count=model_count,\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 1198, in model_forecast\n",
      "    model_count=model_count,\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 702, in ModelPrediction\n",
      "    forecast_length=forecast_length, future_regressor=future_regressor_forecast\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/models/basics.py\", line 1895, in predict\n",
      "    res_idx = np.argpartition(res_sum, num_top, axis=0)[0:num_top]\n",
      "  File \"<__array_function__ internals>\", line 6, in argpartition\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/numpy/core/fromnumeric.py\", line 837, in argpartition\n",
      "    return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "ValueError: kth(=10) out of bounds (9)\n",
      "\n",
      "FAILED: Ensemble BestN component 5 of 5 SectionalMotif with error: ValueError('kth(=10) out of bounds (9)')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 1112, in model_forecast\n",
      "    model_count=model_count,\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 1198, in model_forecast\n",
      "    model_count=model_count,\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 786, in ModelPrediction\n",
      "    str(transformation_dict)\n",
      "ValueError: Model returned NaN due to a preprocessing transformer {'fillna': 'ffill', 'transformations': {'0': 'EWMAFilter', '1': 'AlignLastValue', '2': 'AlignLastValue'}, 'transformation_params': {'0': {'span': 12}, '1': {'rows': 7, 'lag': 28, 'method': 'additive', 'strength': 1.0, 'first_value_only': False}, '2': {'rows': 1, 'lag': 1, 'method': 'additive', 'strength': 0.2, 'first_value_only': False}}}. fail_on_forecast_nan=True\n",
      "\n",
      "FAILED: Ensemble BestN component 6 of 5 LATC with error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'ffill', 'transformations': {'0': 'EWMAFilter', '1': 'AlignLastValue', '2': 'AlignLastValue'}, 'transformation_params': {'0': {'span': 12}, '1': {'rows': 7, 'lag': 28, 'method': 'additive', 'strength': 1.0, 'first_value_only': False}, '2': {'rows': 1, 'lag': 1, 'method': 'additive', 'strength': 0.2, 'first_value_only': False}}}. fail_on_forecast_nan=True\")\n",
      " 2 - Ensemble with avg smape 107.87: \n",
      "Model Number: 3 of 59 with model Ensemble for Validation 1\n",
      "3 - Ensemble with avg smape 112.93: \n",
      "Model Number: 4 of 59 with model VECM for Validation 1\n",
      "4 - VECM with avg smape 109.82: \n",
      "Model Number: 5 of 59 with model VECM for Validation 1\n",
      "5 - VECM with avg smape 109.82: \n",
      "Model Number: 6 of 59 with model Ensemble for Validation 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 1112, in model_forecast\n",
      "    model_count=model_count,\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 1198, in model_forecast\n",
      "    model_count=model_count,\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 702, in ModelPrediction\n",
      "    forecast_length=forecast_length, future_regressor=future_regressor_forecast\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/models/basics.py\", line 1895, in predict\n",
      "    res_idx = np.argpartition(res_sum, num_top, axis=0)[0:num_top]\n",
      "  File \"<__array_function__ internals>\", line 6, in argpartition\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/numpy/core/fromnumeric.py\", line 837, in argpartition\n",
      "    return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "ValueError: kth(=10) out of bounds (9)\n",
      "\n",
      "FAILED: Ensemble BestN component 4 of 3 SectionalMotif with error: ValueError('kth(=10) out of bounds (9)')\n",
      " 6 - Ensemble with avg smape 106.03: \n",
      "Model Number: 7 of 59 with model Ensemble for Validation 1\n",
      "7 - Ensemble with avg smape 110.81: \n",
      "Model Number: 8 of 59 with model VECM for Validation 1\n",
      "8 - VECM with avg smape 170.82: \n",
      "Model Number: 9 of 59 with model DynamicFactor for Validation 1\n",
      "9 - DynamicFactor with avg smape 108.66: \n",
      "Model Number: 10 of 59 with model VECM for Validation 1\n",
      "10 - VECM with avg smape 107.84: \n",
      "Model Number: 11 of 59 with model VECM for Validation 1\n",
      " 11 - VECM with avg smape 105.41: \n",
      "Model Number: 12 of 59 with model VARMAX for Validation 1\n",
      "12 - VARMAX with avg smape 107.91: \n",
      "Model Number: 13 of 59 with model VARMAX for Validation 1\n",
      " 13 - VARMAX with avg smape 99.72: \n",
      "Model Number: 14 of 59 with model VARMAX for Validation 1\n",
      "14 - VARMAX with avg smape 107.86: \n",
      "Model Number: 15 of 59 with model VARMAX for Validation 1\n",
      "15 - VARMAX with avg smape 126.65: \n",
      "Model Number: 16 of 59 with model RRVAR for Validation 1\n",
      "16 - RRVAR with avg smape 104.72: \n",
      "Model Number: 17 of 59 with model VAR for Validation 1\n",
      "17 - VAR with avg smape 105.8: \n",
      "Model Number: 18 of 59 with model VAR for Validation 1\n",
      "18 - VAR with avg smape 105.8: \n",
      "Model Number: 19 of 59 with model MultivariateRegression for Validation 1\n",
      "19 - MultivariateRegression with avg smape 121.97: \n",
      "Model Number: 20 of 59 with model MultivariateRegression for Validation 1\n",
      "20 - MultivariateRegression with avg smape 106.44: \n",
      "Model Number: 21 of 59 with model VARMAX for Validation 1\n",
      "21 - VARMAX with avg smape 112.97: \n",
      "Model Number: 22 of 59 with model DynamicFactor for Validation 1\n",
      "22 - DynamicFactor with avg smape 113.39: \n",
      "Model Number: 23 of 59 with model RRVAR for Validation 1\n",
      "23 - RRVAR with avg smape 105.55: \n",
      "Model Number: 24 of 59 with model RRVAR for Validation 1\n",
      "24 - RRVAR with avg smape 105.55: \n",
      "Model Number: 25 of 59 with model MultivariateRegression for Validation 1\n",
      "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 25: MultivariateRegression\n",
      "Model Number: 26 of 59 with model SectionalMotif for Validation 1\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (9)') in model 26: SectionalMotif\n",
      "Model Number: 27 of 59 with model RRVAR for Validation 1\n",
      "27 - RRVAR with avg smape 103.11: \n",
      "Model Number: 28 of 59 with model RRVAR for Validation 1\n",
      "28 - RRVAR with avg smape 105.33: \n",
      "Model Number: 29 of 59 with model MultivariateRegression for Validation 1\n",
      "29 - MultivariateRegression with avg smape 105.32: \n",
      "Model Number: 30 of 59 with model MultivariateRegression for Validation 1\n",
      "30 - MultivariateRegression with avg smape 120.2: \n",
      "Model Number: 31 of 59 with model VAR for Validation 1\n",
      "31 - VAR with avg smape 103.61: \n",
      "Model Number: 32 of 59 with model VAR for Validation 1\n",
      "32 - VAR with avg smape 103.61: \n",
      "Model Number: 33 of 59 with model VAR for Validation 1\n",
      "33 - VAR with avg smape 103.61: \n",
      "Model Number: 34 of 59 with model LATC for Validation 1\n",
      "34 - LATC with avg smape 103.89: \n",
      "Model Number: 35 of 59 with model WindowRegression for Validation 1\n",
      "35 - WindowRegression with avg smape 106.67: \n",
      "Model Number: 36 of 59 with model LATC for Validation 1\n",
      "36 - LATC with avg smape 111.57: \n",
      "Model Number: 37 of 59 with model DynamicFactor for Validation 1\n",
      "37 - DynamicFactor with avg smape 104.7: \n",
      "Model Number: 38 of 59 with model RollingRegression for Validation 1\n",
      "38 - RollingRegression with avg smape 111.31: \n",
      "Model Number: 39 of 59 with model DynamicFactor for Validation 1\n",
      "39 - DynamicFactor with avg smape 106.86: \n",
      "Model Number: 40 of 59 with model LATC for Validation 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 - LATC with avg smape 102.14: \n",
      "Model Number: 41 of 59 with model DynamicFactor for Validation 1\n",
      "41 - DynamicFactor with avg smape 142.86: \n",
      "Model Number: 42 of 59 with model Cassandra for Validation 1\n",
      "Dropping zero variance feature columns Index(['weekdayofmonth_1', 'weekdayofmonth_2', 'weekdayofmonth_3',\n",
      "       'weekdayofmonth_4', 'weekdayofmonth_5'],\n",
      "      dtype='object')\n",
      "Dropping multi-colinear feature columns Index(['seasonalitycommonfourier_24', 'seasonalitycommonfourier_25',\n",
      "       'randomwalk_0', 'randomwalk_1', 'randomwalk_2', 'randomwalk_3',\n",
      "       'randomwalk_4', 'randomwalk_5', 'randomwalk_6', 'randomwalk_7',\n",
      "       'randomwalk_8', 'randomwalk_9'],\n",
      "      dtype='object')\n",
      " 42 - Cassandra with avg smape 98.76: \n",
      "Model Number: 43 of 59 with model MultivariateMotif for Validation 1\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on fit') in model 43: MultivariateMotif\n",
      "Model Number: 44 of 59 with model Cassandra for Validation 1\n",
      "No anomalies detected.\n",
      "Dropping zero variance feature columns Index(['seasonality7_6'], dtype='object')\n",
      "Dropping multi-colinear feature columns Index(['seasonality365.25_4', 'seasonality365.25_5', 'seasonality365.25_6',\n",
      "       'seasonality365.25_7', 'seasonality365.25_8', 'seasonality365.25_9',\n",
      "       'seasonality365.25_10', 'seasonality365.25_11', 'seasonality365.25_12',\n",
      "       'seasonality365.25_13', 'seasonality365.25_14', 'seasonality365.25_15',\n",
      "       'seasonality365.25_16', 'seasonality365.25_17', 'seasonality365.25_18',\n",
      "       'seasonality365.25_19', 'randomwalk_0', 'randomwalk_1', 'randomwalk_2',\n",
      "       'randomwalk_3', 'randomwalk_4', 'randomwalk_5', 'randomwalk_6',\n",
      "       'randomwalk_7', 'randomwalk_8', 'randomwalk_9'],\n",
      "      dtype='object')\n",
      "44 - Cassandra with avg smape 139.91: \n",
      "Model Number: 45 of 59 with model LATC for Validation 1\n",
      "45 - LATC with avg smape 111.18: \n",
      "Model Number: 46 of 59 with model NVAR for Validation 1\n",
      "46 - NVAR with avg smape 144.05: \n",
      "Model Number: 47 of 59 with model SectionalMotif for Validation 1\n",
      "47 - SectionalMotif with avg smape 119.76: \n",
      "Model Number: 48 of 59 with model SectionalMotif for Validation 1\n",
      "48 - SectionalMotif with avg smape 112.47: \n",
      "Model Number: 49 of 59 with model SectionalMotif for Validation 1\n",
      "49 - SectionalMotif with avg smape 123.68: \n",
      "Model Number: 50 of 59 with model WindowRegression for Validation 1\n",
      "50 - WindowRegression with avg smape 115.27: \n",
      "Model Number: 51 of 59 with model SectionalMotif for Validation 1\n",
      "51 - SectionalMotif with avg smape 109.47: \n",
      "Model Number: 52 of 59 with model WindowRegression for Validation 1\n",
      "52 - WindowRegression with avg smape 164.15: \n",
      "Model Number: 53 of 59 with model WindowRegression for Validation 1\n",
      "53 - WindowRegression with avg smape 111.63: \n",
      "Model Number: 54 of 59 with model LATC for Validation 1\n",
      "54 - LATC with avg smape 134.31: \n",
      "Model Number: 55 of 59 with model WindowRegression for Validation 1\n",
      "55 - WindowRegression with avg smape 153.07: \n",
      "Model Number: 56 of 59 with model MultivariateMotif for Validation 1\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on fit') in model 56: MultivariateMotif\n",
      "Model Number: 57 of 59 with model MultivariateMotif for Validation 1\n",
      "57 - MultivariateMotif with avg smape 126.5: \n",
      "Model Number: 58 of 59 with model MultivariateMotif for Validation 1\n",
      "Template Eval Error: ValueError('kth(=15) out of bounds (12)') in model 58: MultivariateMotif\n",
      "Model Number: 59 of 59 with model MultivariateMotif for Validation 1\n",
      "59 - MultivariateMotif with avg smape 118.41: \n",
      "Validation Round: 2\n",
      "Model Number: 1 of 59 with model Ensemble for Validation 2\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/tools/transform.py\", line 3602, in _fit\n",
      "    df = self.transformers[i].fit_transform(df)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/tools/transform.py\", line 2577, in fit_transform\n",
      "    self.fit(df)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/tools/transform.py\", line 2512, in fit\n",
      "    self.center = self.find_centerpoint(df, self.rows, self.lag)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/tools/transform.py\", line 2520, in find_centerpoint\n",
      "    center = df.iloc[-lag, :]\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/pandas/core/indexing.py\", line 889, in __getitem__\n",
      "    return self._getitem_tuple(key)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/pandas/core/indexing.py\", line 1450, in _getitem_tuple\n",
      "    self._has_valid_tuple(tup)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/pandas/core/indexing.py\", line 723, in _has_valid_tuple\n",
      "    self._validate_key(k, i)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/pandas/core/indexing.py\", line 1358, in _validate_key\n",
      "    self._validate_integer(key, axis)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/pandas/core/indexing.py\", line 1444, in _validate_integer\n",
      "    raise IndexError(\"single positional indexer is out-of-bounds\")\n",
      "IndexError: single positional indexer is out-of-bounds\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 1112, in model_forecast\n",
      "    model_count=model_count,\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 1198, in model_forecast\n",
      "    model_count=model_count,\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 681, in ModelPrediction\n",
      "    df_train_transformed = transformer_object._fit(df_train)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/tools/transform.py\", line 3614, in _fit\n",
      "    ) from e\n",
      "Exception: Transformer AlignLastValue failed on fit\n",
      "\n",
      "FAILED: Ensemble Dist component 3 of 2 MultivariateMotif with error: Exception('Transformer AlignLastValue failed on fit')\n",
      "Template Eval Error: ValueError(\"'3ff89c07663fe3bfe89a7be379c930d9' is not in list\") in model 1: Ensemble\n",
      "Model Number: 2 of 59 with model Ensemble for Validation 2\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 1112, in model_forecast\n",
      "    model_count=model_count,\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 1198, in model_forecast\n",
      "    model_count=model_count,\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 702, in ModelPrediction\n",
      "    forecast_length=forecast_length, future_regressor=future_regressor_forecast\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/models/basics.py\", line 1919, in predict\n",
      "    upper_forecast = nan_quantile(results, q=(1 - pred_int), axis=0)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/tools/percentile.py\", line 112, in nan_quantile\n",
      "    return nan_percentile(arr, q * 100, method=method, axis=axis, errors=errors)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/tools/percentile.py\", line 47, in nan_percentile\n",
      "    max_val = np.nanmax(arr)\n",
      "  File \"<__array_function__ internals>\", line 6, in nanmax\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/numpy/lib/nanfunctions.py\", line 434, in nanmax\n",
      "    res = np.fmax.reduce(a, axis=axis, out=out, **kwargs)\n",
      "ValueError: zero-size array to reduction operation fmax which has no identity\n",
      "\n",
      "FAILED: Ensemble BestN component 5 of 5 SectionalMotif with error: ValueError('zero-size array to reduction operation fmax which has no identity')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 1112, in model_forecast\n",
      "    model_count=model_count,\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 1198, in model_forecast\n",
      "    model_count=model_count,\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 786, in ModelPrediction\n",
      "    str(transformation_dict)\n",
      "ValueError: Model returned NaN due to a preprocessing transformer {'fillna': 'ffill', 'transformations': {'0': 'EWMAFilter', '1': 'AlignLastValue', '2': 'AlignLastValue'}, 'transformation_params': {'0': {'span': 12}, '1': {'rows': 7, 'lag': 28, 'method': 'additive', 'strength': 1.0, 'first_value_only': False}, '2': {'rows': 1, 'lag': 1, 'method': 'additive', 'strength': 0.2, 'first_value_only': False}}}. fail_on_forecast_nan=True\n",
      "\n",
      "FAILED: Ensemble BestN component 6 of 5 LATC with error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'ffill', 'transformations': {'0': 'EWMAFilter', '1': 'AlignLastValue', '2': 'AlignLastValue'}, 'transformation_params': {'0': {'span': 12}, '1': {'rows': 7, 'lag': 28, 'method': 'additive', 'strength': 1.0, 'first_value_only': False}, '2': {'rows': 1, 'lag': 1, 'method': 'additive', 'strength': 0.2, 'first_value_only': False}}}. fail_on_forecast_nan=True\")\n",
      " 2 - Ensemble with avg smape 140.5: \n",
      "Model Number: 3 of 59 with model Ensemble for Validation 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3 - Ensemble with avg smape 139.22: \n",
      "Model Number: 4 of 59 with model VECM for Validation 2\n",
      "4 - VECM with avg smape 157.54: \n",
      "Model Number: 5 of 59 with model VECM for Validation 2\n",
      "5 - VECM with avg smape 157.54: \n",
      "Model Number: 6 of 59 with model Ensemble for Validation 2\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 1112, in model_forecast\n",
      "    model_count=model_count,\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 1198, in model_forecast\n",
      "    model_count=model_count,\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/evaluator/auto_model.py\", line 702, in ModelPrediction\n",
      "    forecast_length=forecast_length, future_regressor=future_regressor_forecast\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/models/basics.py\", line 1919, in predict\n",
      "    upper_forecast = nan_quantile(results, q=(1 - pred_int), axis=0)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/tools/percentile.py\", line 112, in nan_quantile\n",
      "    return nan_percentile(arr, q * 100, method=method, axis=axis, errors=errors)\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/autots/tools/percentile.py\", line 47, in nan_percentile\n",
      "    max_val = np.nanmax(arr)\n",
      "  File \"<__array_function__ internals>\", line 6, in nanmax\n",
      "  File \"/Users/danilculkov/opt/anaconda3/envs/practice/lib/python3.7/site-packages/numpy/lib/nanfunctions.py\", line 434, in nanmax\n",
      "    res = np.fmax.reduce(a, axis=axis, out=out, **kwargs)\n",
      "ValueError: zero-size array to reduction operation fmax which has no identity\n",
      "\n",
      "FAILED: Ensemble BestN component 4 of 3 SectionalMotif with error: ValueError('zero-size array to reduction operation fmax which has no identity')\n",
      "6 - Ensemble with avg smape 156.66: \n",
      "Model Number: 7 of 59 with model Ensemble for Validation 2\n",
      "7 - Ensemble with avg smape 159.81: \n",
      "Model Number: 8 of 59 with model VECM for Validation 2\n",
      "8 - VECM with avg smape 190.86: \n",
      "Model Number: 9 of 59 with model DynamicFactor for Validation 2\n",
      " 9 - DynamicFactor with avg smape 133.81: \n",
      "Model Number: 10 of 59 with model VECM for Validation 2\n",
      " 10 - VECM with avg smape 125.35: \n",
      "Model Number: 11 of 59 with model VECM for Validation 2\n",
      "11 - VECM with avg smape 139.86: \n",
      "Model Number: 12 of 59 with model VARMAX for Validation 2\n",
      "12 - VARMAX with avg smape 157.64: \n",
      "Model Number: 13 of 59 with model VARMAX for Validation 2\n",
      "13 - VARMAX with avg smape 156.65: \n",
      "Model Number: 14 of 59 with model VARMAX for Validation 2\n",
      "14 - VARMAX with avg smape 160.53: \n",
      "Model Number: 15 of 59 with model VARMAX for Validation 2\n",
      "15 - VARMAX with avg smape 130.57: \n",
      "Model Number: 16 of 59 with model RRVAR for Validation 2\n",
      "16 - RRVAR with avg smape 125.49: \n",
      "Model Number: 17 of 59 with model VAR for Validation 2\n",
      "Template Eval Error: ValueError('maxlags is too large for the number of observations and the number of equations. The largest model cannot be estimated.') in model 17: VAR\n",
      "Model Number: 18 of 59 with model VAR for Validation 2\n",
      "Template Eval Error: ValueError('maxlags is too large for the number of observations and the number of equations. The largest model cannot be estimated.') in model 18: VAR\n",
      "Model Number: 19 of 59 with model MultivariateRegression for Validation 2\n",
      " 19 - MultivariateRegression with avg smape 120.75: \n",
      "Model Number: 20 of 59 with model MultivariateRegression for Validation 2\n",
      "20 - MultivariateRegression with avg smape 132.83: \n",
      "Model Number: 21 of 59 with model VARMAX for Validation 2\n",
      "21 - VARMAX with avg smape 130.95: \n",
      "Model Number: 22 of 59 with model DynamicFactor for Validation 2\n",
      "22 - DynamicFactor with avg smape 128.07: \n",
      "Model Number: 23 of 59 with model RRVAR for Validation 2\n",
      " 23 - RRVAR with avg smape 119.97: \n",
      "Model Number: 24 of 59 with model RRVAR for Validation 2\n",
      "24 - RRVAR with avg smape 119.97: \n",
      "Model Number: 25 of 59 with model MultivariateRegression for Validation 2\n",
      "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 25: MultivariateRegression\n",
      "Model Number: 26 of 59 with model SectionalMotif for Validation 2\n",
      "Template Eval Error: ValueError('zero-size array to reduction operation fmax which has no identity') in model 26: SectionalMotif\n",
      "Model Number: 27 of 59 with model RRVAR for Validation 2\n",
      "27 - RRVAR with avg smape 158.02: \n",
      "Model Number: 28 of 59 with model RRVAR for Validation 2\n",
      "28 - RRVAR with avg smape 152.37: \n",
      "Model Number: 29 of 59 with model MultivariateRegression for Validation 2\n",
      "29 - MultivariateRegression with avg smape 160.57: \n",
      "Model Number: 30 of 59 with model MultivariateRegression for Validation 2\n",
      "30 - MultivariateRegression with avg smape 161.06: \n",
      "Model Number: 31 of 59 with model VAR for Validation 2\n",
      "Template Eval Error: ValueError('maxlags is too large for the number of observations and the number of equations. The largest model cannot be estimated.') in model 31: VAR\n",
      "Model Number: 32 of 59 with model VAR for Validation 2\n",
      "Template Eval Error: ValueError('maxlags is too large for the number of observations and the number of equations. The largest model cannot be estimated.') in model 32: VAR\n",
      "Model Number: 33 of 59 with model VAR for Validation 2\n",
      "Template Eval Error: ValueError('maxlags is too large for the number of observations and the number of equations. The largest model cannot be estimated.') in model 33: VAR\n",
      "Model Number: 34 of 59 with model LATC for Validation 2\n",
      "34 - LATC with avg smape 161.06: \n",
      "Model Number: 35 of 59 with model WindowRegression for Validation 2\n",
      " 35 - WindowRegression with avg smape 115.93: \n",
      "Model Number: 36 of 59 with model LATC for Validation 2\n",
      "36 - LATC with avg smape 132.93: \n",
      "Model Number: 37 of 59 with model DynamicFactor for Validation 2\n",
      "37 - DynamicFactor with avg smape 136.26: \n",
      "Model Number: 38 of 59 with model RollingRegression for Validation 2\n",
      "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 38: RollingRegression\n",
      "Model Number: 39 of 59 with model DynamicFactor for Validation 2\n",
      "39 - DynamicFactor with avg smape 129.19: \n",
      "Model Number: 40 of 59 with model LATC for Validation 2\n",
      "40 - LATC with avg smape 136.83: \n",
      "Model Number: 41 of 59 with model DynamicFactor for Validation 2\n",
      "41 - DynamicFactor with avg smape 131.64: \n",
      "Model Number: 42 of 59 with model Cassandra for Validation 2\n",
      "Dropping zero variance feature columns Index(['weekdayofmonth_1', 'weekdayofmonth_2', 'weekdayofmonth_3',\n",
      "       'weekdayofmonth_4', 'weekdayofmonth_5'],\n",
      "      dtype='object')\n",
      "Dropping multi-colinear feature columns Index(['seasonalitycommonfourier_14', 'seasonalitycommonfourier_15',\n",
      "       'seasonalitycommonfourier_16', 'seasonalitycommonfourier_17',\n",
      "       'seasonalitycommonfourier_18', 'seasonalitycommonfourier_19',\n",
      "       'seasonalitycommonfourier_20', 'seasonalitycommonfourier_21',\n",
      "       'seasonalitycommonfourier_22', 'seasonalitycommonfourier_23',\n",
      "       'seasonalitycommonfourier_24', 'seasonalitycommonfourier_25',\n",
      "       'randomwalk_0', 'randomwalk_1', 'randomwalk_2', 'randomwalk_3',\n",
      "       'randomwalk_4', 'randomwalk_5', 'randomwalk_6', 'randomwalk_7',\n",
      "       'randomwalk_8', 'randomwalk_9'],\n",
      "      dtype='object')\n",
      "42 - Cassandra with avg smape 160.17: \n",
      "Model Number: 43 of 59 with model MultivariateMotif for Validation 2\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on fit') in model 43: MultivariateMotif\n",
      "Model Number: 44 of 59 with model Cassandra for Validation 2\n",
      "No anomalies detected.\n",
      "Dropping zero variance feature columns Index(['seasonality7_6'], dtype='object')\n",
      "Dropping multi-colinear feature columns Index(['seasonality7_15', 'seasonality7_16', 'seasonality7_17',\n",
      "       'seasonality7_18', 'seasonality7_19', 'seasonality365.25_0',\n",
      "       'seasonality365.25_1', 'seasonality365.25_2', 'seasonality365.25_3',\n",
      "       'seasonality365.25_4', 'seasonality365.25_5', 'seasonality365.25_6',\n",
      "       'seasonality365.25_7', 'seasonality365.25_8', 'seasonality365.25_9',\n",
      "       'seasonality365.25_10', 'seasonality365.25_11', 'seasonality365.25_12',\n",
      "       'seasonality365.25_13', 'seasonality365.25_14', 'seasonality365.25_15',\n",
      "       'seasonality365.25_16', 'seasonality365.25_17', 'seasonality365.25_18',\n",
      "       'seasonality365.25_19', 'randomwalk_0', 'randomwalk_1', 'randomwalk_2',\n",
      "       'randomwalk_3', 'randomwalk_4', 'randomwalk_5', 'randomwalk_6',\n",
      "       'randomwalk_7', 'randomwalk_8', 'randomwalk_9'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 - Cassandra with avg smape 187.41: \n",
      "Model Number: 45 of 59 with model LATC for Validation 2\n",
      "45 - LATC with avg smape 198.94: \n",
      "Model Number: 46 of 59 with model NVAR for Validation 2\n",
      "46 - NVAR with avg smape 120.31: \n",
      "Model Number: 47 of 59 with model SectionalMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (1)') in model 47: SectionalMotif\n",
      "Model Number: 48 of 59 with model SectionalMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (1)') in model 48: SectionalMotif\n",
      "Model Number: 49 of 59 with model SectionalMotif for Validation 2\n",
      "Template Eval Error: ValueError('zero-size array to reduction operation fmax which has no identity') in model 49: SectionalMotif\n",
      "Model Number: 50 of 59 with model WindowRegression for Validation 2\n",
      "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 2 is required.') in model 50: WindowRegression\n",
      "Model Number: 51 of 59 with model SectionalMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (1)') in model 51: SectionalMotif\n",
      "Model Number: 52 of 59 with model WindowRegression for Validation 2\n",
      "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 2 is required.') in model 52: WindowRegression\n",
      "Model Number: 53 of 59 with model WindowRegression for Validation 2\n",
      "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 2 is required.') in model 53: WindowRegression\n",
      "Model Number: 54 of 59 with model LATC for Validation 2\n",
      "54 - LATC with avg smape 135.55: \n",
      "Model Number: 55 of 59 with model WindowRegression for Validation 2\n",
      "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 2 is required.') in model 55: WindowRegression\n",
      "Model Number: 56 of 59 with model MultivariateMotif for Validation 2\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on fit') in model 56: MultivariateMotif\n",
      "Model Number: 57 of 59 with model MultivariateMotif for Validation 2\n",
      "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 57: MultivariateMotif\n",
      "Model Number: 58 of 59 with model MultivariateMotif for Validation 2\n",
      "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 58: MultivariateMotif\n",
      "Model Number: 59 of 59 with model MultivariateMotif for Validation 2\n",
      "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 59: MultivariateMotif\n",
      "Model Number: 1 with model Ensemble in generation 0 of Horizontal Ensembles\n",
      "Model Number: 2 with model Ensemble in generation 0 of Horizontal Ensembles\n"
     ]
    }
   ],
   "source": [
    "model = model.fit(\n",
    "    y_train,\n",
    "    future_regressor=future_regressor_train2d,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acting-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_regressor_test2d, future_regressor_forecast2d = fake_regressor(\n",
    "    X_test,\n",
    "    frequency='Q-DEC',\n",
    "    forecast_length=X_test.shape[0],\n",
    "    dimensions=X_test.shape[1],\n",
    "    drop_most_recent=model.drop_most_recent,\n",
    "    aggfunc=model.aggfunc,\n",
    "    verbose=model.verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "concerned-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(forecast_length=future_regressor_forecast2d.shape[0], future_regressor=future_regressor_forecast2d, verbose=0)\n",
    "forecasts_df = prediction.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "least-summer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INCOME STATEMENT///Operating Income</th>\n",
       "      <th>INCOME STATEMENT///Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>49.680602</td>\n",
       "      <td>240.973290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>47.803773</td>\n",
       "      <td>266.620800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-31</th>\n",
       "      <td>46.473687</td>\n",
       "      <td>270.234800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30</th>\n",
       "      <td>45.627805</td>\n",
       "      <td>270.110938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-30</th>\n",
       "      <td>45.204502</td>\n",
       "      <td>269.352237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071-06-30</th>\n",
       "      <td>60.908818</td>\n",
       "      <td>115.499076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071-09-30</th>\n",
       "      <td>60.908818</td>\n",
       "      <td>114.822686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071-12-31</th>\n",
       "      <td>60.908818</td>\n",
       "      <td>114.147155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072-03-31</th>\n",
       "      <td>60.908818</td>\n",
       "      <td>113.475162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072-06-30</th>\n",
       "      <td>60.908818</td>\n",
       "      <td>112.804026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            INCOME STATEMENT///Operating Income  INCOME STATEMENT///Revenue\n",
       "2020-09-30                            49.680602                  240.973290\n",
       "2020-12-31                            47.803773                  266.620800\n",
       "2021-03-31                            46.473687                  270.234800\n",
       "2021-06-30                            45.627805                  270.110938\n",
       "2021-09-30                            45.204502                  269.352237\n",
       "...                                         ...                         ...\n",
       "2071-06-30                            60.908818                  115.499076\n",
       "2071-09-30                            60.908818                  114.822686\n",
       "2071-12-31                            60.908818                  114.147155\n",
       "2072-03-31                            60.908818                  113.475162\n",
       "2072-06-30                            60.908818                  112.804026\n",
       "\n",
       "[208 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "federal-stevens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164.72483701188014"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smape(y_test, forecasts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-bibliography",
   "metadata": {},
   "source": [
    "SMAPE has significantly increased. \n",
    "\n",
    "__Apparent outcome__: our data is quite specific so it requires carefull processing and modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice",
   "language": "python",
   "name": "practice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
